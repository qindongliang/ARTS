
 [Algorithm KindDeckCards ](#algorithm)

 [Review 关于spark的参数问题的描述](#review)

 [Technique 复盘一个Elasticsearch排序问题的剖析](#technique)

 [Share 什么是缓存置换算法](#share)


# Algorithm

```java
package leetcode.easy.array_all;

import java.util.HashMap;
import java.util.Map;

/****
 * https://leetcode.com/problems/x-of-a-kind-in-a-deck-of-cards/
 * 给定一组卡牌，让求出里面相同数字的所有分组，分组的数量不得小于2
 *
 * 思路：遍历一遍数组，求出每个数字的数量
 * 然后，对数量之间求出最大公约数，最后如果最大公约数2即可。
 */
public class KindDeckCards {

    public static boolean hasGroupsSizeX(int[] deck) {
        Map<Integer,Integer> count=new HashMap<>();
        for (int i :deck) {
            count.put(i,count.getOrDefault(i,0)+1);
        }
        int res=0;
        for (int i:count.values()){
            res=gcd(i,res);
        }

        return res>1;
    }

    //最大公约数算法->辗转相除法
    public static   int gcd(int a, int b){
        if(b==0){
            return a;
        }
        return gcd(b,a%b);
    }


    public static void main(String[] args) {
        int arr[]={0,0,0,1,1,1,2,2,2};
        System.out.println(hasGroupsSizeX(arr));

    }
}
```


# Review

https://stackoverflow.com/questions/37132559/add-jars-to-a-spark-job-spark-submit

这周看了有关spark的参数路径问题，官网文档描述的模棱两可，搜了下stackoverflow，发现这个链接介绍的还可以
但，还是没有解答我心中的疑问，我又提了一个链接：
https://stackoverflow.com/questions/57069649/how-to-understand-the-relationship-and-use-of-spark-jars-extraclasspath-and-e


# Technique

最近线上的es查询的某个微服务接口，报了一个异常，如下：


```
nested: SearchParseException[No mapping found for [count] in order to sort on];
Caused by: SearchParseException[failed to parse search source 
```

直接从异常上看，可以得到是因为mapping里面不存在排序字段的时候，而抛出的异常，正常的情况，如果某个索引不存在并且还去查询该索引，我们可以通过对索引名字后面加*通配，来避免查询报错，如下：
```
        SearchRequestBuilder search=client.prepareSearch("log2019-07-11*");
        search.setQuery(QueryBuilders.queryStringQuery("uid:111"));
        search.addSort("count", SortOrder.DESC);
```
经询问，我们的代码里面已经加了*通配符，那么又为什么会出现这个问题呢？经过对场景的分析总结，对某个字段进行sort时，可能会报上述异常，主要在两种情况下：

（1）count字段在mapping中无定义，并没有在索引名字后缀加*通配符时，必定每次都报异常

（2）count字段在mapping中有定义，使用前面的排序方法，排序有时候报错，有时候不报

对于第一种情况，mapping里不存在定义，并且没有使用通配容错，直接使用该字段排序报错很正常。

接下来主要分析第二种情况，因为这里面有个概率事件，即大多数时候都没问题，但在少数时候会抛出异常。通过分析log发现在凌晨12点刚过的时候，会有几率出现这种问题，为了找到更多的排查线索，我让运维给出了线上当时服务端es的log文件，毕竟单纯从微服务的log里面，很难观察到这个异常前后，有没有更多的上下文log输出，想要找到这个，只能查看服务端部署es节点的log了，在拿到log之后，果然从上下文里面，发现了一些关键的信息，如下：
```
[2019-07-11 00:00:05,044][INFO ][cluster.metadata         ] [my_es] [log2019-07-11] creating index, cause [auto(index api)], templates [log], shards [3]/[2], mappings [_default_, log]
[2019-07-11 00:00:05,409][INFO ][cluster.routing.allocation] [my_es] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[log2019-07-11][0], [log2019-07-11][2], [log2019-07-11][1]] ...]).
[2019-07-11 00:00:06,232][INFO ][cluster.routing.allocation] [my_es] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[log2019-07-11][1], [log2019-07-11][1]] ...]).
[2019-07-11 00:00:06,374][INFO ][cluster.metadata         ] [my_es] [log2019-07-11] update_mapping [log]
[2019-07-11 00:00:07,153][DEBUG][action.search            ] [my_es] [log2019-07-11][0], node[QlHmfObMRg2K6FUuAaXXTw], [R], v[2], s[INITIALIZING], a[id=3aenuvbUQtGrFDBBxjJvCA], unassigned_info[[reason=INDEX_CREATED], at[2019-07-10T16:00:06.574Z]]: Failed to execute [org.elasticsearch.action.search.SearchRequest@22e9ea6f] lastShard [trueRemoteTransportException[[my_es_02][192.168.10.152:9300][indices:data/read/search[phase/query]]]; nested: SearchParseException[failed to parse search source [{"size":3,"query":{"bool":{"should":[{"term":{"uid":"44733065"}}]}},"sort":[{"count":{"order":"desc"}}]}]]; nested: SearchParseException[No mapping found for [count] in order to sort on];
Caused by: SearchParseException[failed to parse search source 

```

注意，在报这个异常之前，有两行关键的log：
```
[2019-07-11 00:00:05,409][INFO ][cluster.routing.allocation] [my_es] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[log2019-07-11][0], [log2019-07-11][2], [log2019-07-11][1]] ...]).
[2019-07-11 00:00:06,232][INFO ][cluster.routing.allocation] [my_es] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[log2019-07-11][1], [log2019-07-11][1]] ...]).

```
期间报异常的前2秒，es集群状态经历了从red到yellow再到green，虽然只有短暂的1秒，但却是排查问题非常关键的信息，我们知道出现这种信息的时候，代表的是es的主分片和副本分片正在做初始化或者出现了异常等待恢复，由此可以推论出这样一个场景，当凌晨12点刚过的第5秒，有写入该索引的es数据，触发了es动态索引的创建，由于这个索引有3个shard，每个shard分别有2个副本shard，也就是说共有6个shard需要初始化，假设初始化需要的时间为2秒，那么，恰巧在第6秒的时候，有个查询带排序的请求过来了，这个时候由于索引初始化并没有完成，所以在当天部分shard的mapping里面并没有查到该字段的信息，故产生了异常，之后当这个索引创建完成之后，再次收到的新查询请求是没有问题的。为了验证我们这个猜想，我们需要一段程序来做测试：

设计的复现场景有如下两步：

（1）A线程模拟查询请求，一直都在查询某一天的索引数据，起初这个索引并不存在，因为不存在所以查询使用通配符的方法，即使有排序字段，也并不会报错。
A线程的查询代码如下：
```
        SearchRequestBuilder search=client.prepareSearch("log2019-07-11*");
        search.setQuery(QueryBuilders.queryStringQuery("uid:111"));
        search.addSort("count", SortOrder.DESC);
        SearchResponse sr=search.get();
        for ( SearchHit hit: sr.getHits()){
            System.out.println(hit.getSource().toString());
        }
        System.out.println(Thread.currentThread().getName()+"=>query"+"   hit="+sr.getHits().getTotalHits());
```

（2）B线程在A线程启动3秒后执行，然后向这个不存在的索引插入一条数据，由于第一次插入数据，这天的索引会被自动创建，里面就会涉及shard的初始化过程，这个时候同时A线程在查询就会复现出问题：
```
[No mapping found for [count] in order to sort on]
```

B线程的写入代码如下：
```
        IndexRequestBuilder builder = client.prepareIndex("log2019-07-11", "log").setId("111");
        builder.setCreate(true);
        java.util.Map<String , Object> map=new HashMap<>();
        map.put("uid","111");
        map.put("count","3");
        builder.setSource(map);
        builder.execute().actionGet();
        System.out.println(Thread.currentThread().getName()+" => " + "create index finished. " );
```

知道问题后，那么如何解决这个问题呢？其实非常简单，我们只需要对于排序不存在的字段，作一下缺失容错即可，如下：
```
search.addSort("count", SortOrder.DESC);
```
改为
```
search.addSort(SortBuilders.fieldSort("count").unmappedType("integer").order(SortOrder.DESC));
```
上面的代码，告诉es如果在排序时，遇到一个不存在的字段，我们只需要给其设置正确的排序类型即可，这样就能避免前面提到的2个导致排序失败的原因：

（1）count排序字段在mapping中无定义，并没有在索引名字后缀加*通配符时，必定每次都报异常（查询一个不存在字段，是不会报异常的，不管索引名有无后缀通配符）

（2）count排序字段在mapping中有定义，使用前面的排序方法，排序有时候报错，有时候不报（真正原因是当时shard正在做初始化导致的）



es索引本身是shemeless的结构，对于正常查询一个不存在的字段，是不会报错的，但是对于排序的字段，则有可能出现异常，所以我们在写相关的代码时，可以对排序字段加个容错处理，以提高我们程序的健壮性。


# Share


### 前言

前面的文章已经介绍了什么是操作系统的虚拟内存，与本文要介绍的缓存置换算法息息相关，如果还没有看的朋友，建议先读一下上篇文章，链接是：

xxxx

从上篇文章中，我们学习到虚拟内存的page置换算法，就是缓存过期算法的别称，可以说最早的缓存过期算法，其实是先出现操作系统中，这也是为什么，我强调学习一个东西的时候，最好能了解一下它的历史，这样能更好的帮助我们理解。

### 为什么需要缓存

（1）为了解决不同的存储介质之间的速度不匹配问题，比如CPU和内存，比如内存和磁盘，客户端和服务端。

（2）依据程序访问的局部性原理，近期访问的数据，在将来很有可能会被访问

（3）提升访问效率

### 缓存为什么需要置换

相信读过上篇文章的朋友应该可以很轻松的回答出来这个问题，操作系统本质上是一个多级缓存系统，从cpu寄存器，cpu一级缓存，cpu二级缓存，cpu三级缓存，主内存，硬盘，我们会发现从右到左，访问效率依次提升，同时设备价格也不断升高，从左到右，访问效率依次降低，同时设备价格也逐渐下降。正是出于这个原因，现代计算机都会在性价比之间做个权衡。因为越高访问效率的存储介质越贵，所以这些介质都是有限的资源，那么如何在有限的资源内处理无限的数据呢？这就提出了置换的概念，举个通俗的例子。去医院排队体验，在有限的房间里面，每次只能进入一个人做某项检查，当这个人检查完了，就离开房间，然后置换另一个人进来，依次类推，完成检查。最理想的情况是置换出未来短期内不会被再次访问的数据，但是我们无法预知未来，所以只能从数据在过去的访问情况中寻找规律进行置换。


### 常见的置换算法

缓存置换算法常用的策略有三种，分别是：

 (1) FIFO：First In First Out，先进先出策略
 
 (2) LFU：Least Frequently Used，最不经常使用策略

 (3) LRU：Least Recently Used，最近最少使用策略
 
 这三种淘汰数据的策略和侧重点各不一样，今天我们就来学习相关的知识。
 
### FIFO
 
 FIFO（First in First out）代表先进先出，提起这个概念，相信大家第一时间能够想到队列这种数据结构，在日常生活中，这种场景随处都可见，比如吃饭排队，去银行取钱排队，上地铁排队。这种策略，非常简单易懂，实现简单，而且具有公平性，符合人们思维的习惯。在计算机中这种思想也到处可见，比如在操作系统的调度系统中，IO读取等操作。其核心原则就是：最先进入缓存的数据，应该最早被淘汰。
 
 考虑这样一串数字4, 7, 6, 1, 7, 6, 1, 2, 7, 2。如何在一个固定长度为3的容器中进行FIFO策略的淘汰？如下：
 ![image](https://static.javatpoint.com/operating-system/images/os-numerical-on-fifo.png)
 
 我们观察到前面6，7，4放进去之后，这是1的加入会淘汰原来最早放进去的4，接着7的到来，发现缓存命中所以不做处理，直到2出现，这个时候我们需要淘汰原来的7，就这样按照先进先出的策略淘汰。
 
 
### LFU
 LFU 全称 Least Frequently Used，从名字上我们就能看出来这个算法是基于数据访问频率（次数）来淘汰数据的，也就是说系统会记录一段时间内所有数据的访问次数，当缓存区满的时候，会优先淘汰访问次数最少的数据。
 其核心思想：如果一个数据在最近一段时间内访问次数很少，则在将来一段时间内被访问的可能性也很小。显然，这是一种合理的算法，因为到目前为止最少使用的页面，很可能也是将来最少访问的页面。缓存的每个数据都有引用计数，所有数据按照引用计数排序，具有相同引用计数的数据按照时间排序。
 
 ![image](https://slideplayer.com/slide/6026617/20/images/58/Page+Replacement+Algorithms+Counting+Algorithms%3A+LFU+scheme.jpg)
 
 
### LRU 
 
 LRU 全称 Least Recently Used，基于数据访问历史记录来执行淘汰策略，LRU是首先淘汰最长时间未被使用的页面，这种算法把近期最久没有被访问过的页面作为被替换的页面，与LFU不一样的是，LRU并不关注缓存数据的访问次数，它只关注该条数据的访问时间。核心思想：如果一个数据在最近一段时间内没被访问，则在将来一段时间内被访问的可能性也很小。
 ![image](https://slideplayer.com/slide/1659380/7/images/13/Least+Recently+Used+%28LRU%29+Algorithm.jpg)
 
 
 
 
### FIFO VS LRU VS LFU
 
 FIFO完全是公平的策略，不考虑特定时间段内访问频次和访问时间，适合用在某些公平调度的场景下。
 
 当存在热点数据时，LRU的效率很好，但偶发性的、周期性的批量操作会导致LRU命中率急剧下降，缓存污染情况比较严重，此时适合使用LFU来做缓存。此外从实现的复杂度上来分析，LFU 需要维护一个队列记录所有数据的访问记录，每个数据都要维护引用计数，内存消耗和性能消耗都较高，而LRU相对来说，实现比较简单，因为不需要考虑计数的问题，仅仅考虑访问时间，非常适合使用双向链表+HashMap来实现O（1）性能的LRU
 
### 总结
 
 本文主要介绍了缓存置换算法的相关概念，原理和置换策略等相关内容，最后并对比分析了常见置换算法的优缺点。缓存作为一种互联网开发必备的组件，理解其置换算法的原理至关重要，值得每一位同学学习和研究。
 
 
 
 

 
 
 

 
 








